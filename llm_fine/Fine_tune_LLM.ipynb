{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fine_tune import model_performance, fine_tune_llm_model,ConversationDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model_name = \"distilbert-base-uncased\"\n",
    "# model_name = \"bert-base-uncased\"\n",
    "\n",
    "model_name = \"bert-base-uncased\" \n",
    "#max_length = 128  # You can increase it up to 512 if needed\n",
    "batch_size = 16\n",
    "max_length=128\n",
    "model_pretrained = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6).to(device)\n",
    "\n",
    "model_tokeniser = AutoTokenizer.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/Users/ritkumar17/Desktop/R&D_Project/LLM_fine/data/train-00000-of-00001-a5a7c6e4bb30b016.parquet\", columns= [\"issue_area\", \"conversation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.head(1)[\"conversation\"]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"conversation\"] = df[\"conversation\"].apply(lambda text : re.sub(r\"^(Agent:|Customer:)\\s*\", \"\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df['issue_area'].value_counts(normalize=True) * 100  \n",
    "colors = [\"#B0E0E6\", \"#87CEEB\", \"#ADD8E6\", \"#AFEEEE\", \"#BFEFFF\", \"#E0FFFF\"]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%', \n",
    "        colors=colors, startangle=140)\n",
    "plt.title(\"Issue Percentage Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_length'] = df[\"conversation\"].apply(lambda text : len(model_tokeniser.tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['token_length'], bins=30, kde=True, color=\"blue\", edgecolor=\"black\")\n",
    "\n",
    "plt.xlabel(\"Token Length\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.title(\"Token Length Distribution\", fontsize=14)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Observations\n",
    "*   Peak around 450 tokens (most common length).\n",
    "*   Long-tail effect with some very long samples (~1200 tokens).\n",
    "*   Almost no short texts (<100 tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Labels\n",
    "labels = df[\"issue_area\"].unique().tolist()\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()} # BERT treats labels as distinct categories, not numbers.\n",
    "df[\"label\"] = df[\"issue_area\"].map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"issue_area\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df[[\"conversation\", \"label\", \"issue_area\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_parquet(\"clean_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(df_data[\"conversation\"], df_data[\"label\"], test_size=.2, random_state=22,stratify=df_data[\"label\"])\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=.1, random_state=22,stratify=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ConversationDataset(train_x, train_y, model_tokeniser)\n",
    "val_dataset= ConversationDataset(val_x, val_y, model_tokeniser)\n",
    "test_dataset = ConversationDataset(test_x, test_y, model_tokeniser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data into DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset,batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_model = fine_tune_llm_model(num_epochs =10 ,train_loader= train_loader,val_loader= val_loader, model=model_pretrained, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit=model_performance(fine_tune_model, test_loader,device, id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine_tune_model.save_pretrained(\"LLM_fine_Tune_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
